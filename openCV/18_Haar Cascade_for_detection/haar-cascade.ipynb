{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach:-\n",
    "#### step1--->\n",
    "Opens the default camera (usually your laptop webcam).\n",
    "\n",
    "0 means the first camera. If you had multiple, you could use 1, 2, etc.\n",
    "\n",
    "#### step2-->\n",
    "Loads a pre-trained Haar Cascade model for detecting faces.\n",
    "\n",
    "Haar cascades are classical ML-based object detectors (before deep learning became mainstream).\n",
    "\n",
    "This XML file contains the rules/patterns to recognize a frontal human face.\n",
    "\n",
    "\n",
    "#### step3-->\n",
    "Starts a loop that continuously reads frames from the camera.\n",
    "\n",
    "ret = Boolean (True if a frame is successfully captured).\n",
    "\n",
    "frame = The actual image captured from the camera.\n",
    "\n",
    "#### step4-->\n",
    "Safety check. If the camera fails to grab a frame, exit the loop.\n",
    "\n",
    "Converts the color image (BGR) to grayscale.\n",
    "\n",
    "Face detection works better & faster on grayscale images, since color is not important for detection.\n",
    "\n",
    "#### step5-->\n",
    "Detects faces in the grayscale frame.\n",
    "\n",
    "Returns a list of rectangles, each rectangle = (x, y, w, h) for one face.\n",
    "\n",
    "(x, y) = top-left corner of face\n",
    "\n",
    "w, h = width and height of the face box\n",
    "\n",
    "Parameters:\n",
    "\n",
    "scaleFactor=1.3: How much the image size is reduced at each scale. Larger = faster, smaller = more accurate.\n",
    "\n",
    "minNeighbors=5: How many neighbors each candidate rectangle should have to be kept (filters out false positives).\n",
    "\n",
    "#### step6-->\n",
    "Loops over each detected face.\n",
    "\n",
    "Draws a blue rectangle ((255,0,0)) around the face.\n",
    "\n",
    "Adds text \"Face Detected\" just above the rectangle in green.\n",
    "\n",
    "\n",
    "#### step7-->\n",
    "Displays the video feed with the detected faces in a window called \"Camera\"\n",
    "\n",
    "Waits for key press.\n",
    "\n",
    "If the user presses 'q', break the loop (quit the program).\n",
    "\n",
    "Releases the webcam resource.\n",
    "\n",
    "Closes all OpenCV windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    if not ret:\n",
    "        print('Video is not captured properly')\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray,scaleFactor=1.3,minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,z) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w, y+h), (255,0,0), 2)\n",
    "        cv2.putText(frame,'Face Detected', (x,y-100), cv2.FONT_HERSHEY_COMPLEX_SMALL,0.9,(0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('camera',frame)\n",
    "\n",
    "    if cv2.waitkey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
